# üöó Test Technique Assurance Auto - Analyse Pr√©dictive des Primes

## üìã Vue d'ensemble du projet

Ce projet pr√©sente une analyse compl√®te de donn√©es d'assurance automobile visant √† pr√©dire les primes commerciales. L'√©tude comprend une exploration approfondie des donn√©es, la construction de mod√®les pr√©dictifs et une analyse de d√©rive (drift) pour √©valuer la robustesse des mod√®les dans le temps.

### üéØ Objectifs principaux

1. **Pr√©diction des primes d'assurance** : D√©velopper des mod√®les capables d'estimer les primes commerciales bas√©es sur les caract√©ristiques des conducteurs et des v√©hicules
2. **Analyse exploratoire** : Comprendre les facteurs influen√ßant les primes d'assurance
3. **D√©tection de d√©rive** : √âvaluer la stabilit√© des mod√®les face aux changements temporels dans les donn√©es
4. **Comparaison de mod√®les** : Tester diff√©rentes approches (GLM vs LightGBM) pour optimiser les performances

## üìä Structure du projet

```
test_technique_assurance_auto_lucas_bonere/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ parameters.py          # Configuration centralis√©e
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ raw/                   # Donn√©es brutes
‚îÇ       ‚îú‚îÄ‚îÄ X_train.csv        # Donn√©es d'entra√Ænement
‚îÇ       ‚îú‚îÄ‚îÄ X_test.csv         # Donn√©es de test
‚îÇ       ‚îî‚îÄ‚îÄ X_drift.csv        # Donn√©es de d√©rive
‚îú‚îÄ‚îÄ models/                    # Mod√®les entra√Æn√©s
‚îÇ   ‚îú‚îÄ‚îÄ glm_model.pkl
‚îÇ   ‚îú‚îÄ‚îÄ lgbm_model.pkl
‚îÇ   ‚îî‚îÄ‚îÄ model_performance.json
‚îú‚îÄ‚îÄ notebooks/                 # Analyses Jupyter
‚îÇ   ‚îú‚îÄ‚îÄ 01_exploration_initiale.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_analyse_univariee.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_analyse_bivariee.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 04_model_training.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 05_drift_analysis.ipynb
‚îú‚îÄ‚îÄ result/
‚îÇ   ‚îî‚îÄ‚îÄ submission.csv         # Pr√©dictions finales
‚îî‚îÄ‚îÄ src/                       # Code source
    ‚îú‚îÄ‚îÄ cleaning.py           # Pipeline de nettoyage
    ‚îî‚îÄ‚îÄ model.py              # Fonctions de mod√©lisation
```

## üîç Analyse des donn√©es

### Variables disponibles

**Variables d√©mographiques :**
- `AgeConducteur` : √Çge du conducteur
- `SexeConducteur` : Genre du conducteur
- `StatutMatrimonial` : Statut marital

**Variables d'assurance :**
- `BonusMalus` : Coefficient bonus/malus
- `FrequencePaiement` : Fr√©quence de paiement
- `CodeProfession` : Code professionnel

**Variables v√©hicule :**
- `AgeVehicule` : √Çge du v√©hicule
- `ClasseVehicule` : Classe du v√©hicule
- `PuissanceVehicule` : Puissance du v√©hicule
- `CarburantVehicule` : Type de carburant
- `UsageVehicule` : Usage du v√©hicule

**Variables contextuelles :**
- `Garage` : Type de garage
- `Region` : R√©gion g√©ographique

**Variable cible :**
- `PrimeCommerciale` : Prime d'assurance √† pr√©dire

### Nettoyage des donn√©es

Le pipeline de nettoyage (`src/cleaning.py`) applique les transformations suivantes :

1. **Suppression de colonnes** : Variables constantes ou trop manquantes (>50%)
2. **Gestion des corr√©lations** : Suppression de variables trop corr√©l√©es (>90%)
3. **Variables supprim√©es** : `PolicyId`, `CodeProfession`, `StatutMatrimonial`

## ü§ñ Mod√©lisation

### Approche adopt√©e

Deux mod√®les compl√©mentaires ont √©t√© d√©velopp√©s :

#### 1. Mod√®le GLM (Tweedie/Gamma)
- **Distribution** : Tweedie avec power=2 (distribution Gamma)
- **Fonction de lien** : Log-link
- **R√©gularisation** : L1/L2 avec alpha optimis√© par validation crois√©e
- **Avantages** : Interpr√©tabilit√©, robustesse statistique

#### 2. Mod√®le LightGBM
- **Algorithme** : Gradient Boosting optimis√©
- **Encodage** : Label encoding automatique des variables cat√©gorielles
- **Hyperparam√®tres** : Optimis√©s par GridSearchCV
- **Avantages** : Performance √©lev√©e, gestion automatique des interactions

### M√©triques d'√©valuation

- **RMSE** : Root Mean Square Error
- **MAE** : Mean Absolute Error  
- **R¬≤** : Coefficient de d√©termination
- **MAPE** : Mean Absolute Percentage Error

### Performances initiales

| M√©trique | GLM | LightGBM |
|----------|-----|----------|
| RMSE     | 108.91 | 107.91 |
| MAE      | 73.40 | 73.40 |
| R¬≤       | 0.75 | 0.75 |
| MAPE     | 17.98% | 17.98% |

## üìà Analyse de d√©rive (Drift Analysis)

### D√©tection de d√©rive

L'analyse de d√©rive r√©v√®le des changements significatifs dans les donn√©es :

#### Variables avec d√©rive d√©tect√©e (5/11 - 45%)

**Variables num√©riques (100% touch√©es) :**
- `AgeConducteur` : Distribution des √¢ges modifi√©e
- `BonusMalus` : Profil de risque des conducteurs √©volu√©
- `AgeVehicule` : Parc automobile rajeuni

**Variables cat√©gorielles (25% touch√©es) :**
- `FrequencePaiement` : Habitudes de paiement modifi√©es
- `ClasseVehicule` : Types de v√©hicules assur√©s diff√©rents

#### Variables stables (6/11 - 55%)
- Variables d√©mographiques et g√©ographiques
- Caract√©ristiques techniques des v√©hicules
- Conditions d'usage et de stationnement

### Impact sur les performances

**D√©gradation majeure des m√©triques :**

| M√©trique | Initial | Drift | D√©gradation |
|----------|---------|-------|-------------|
| RMSE     | 107.91‚Ç¨ | 266.62‚Ç¨ | +147% |
| MAE      | 73.40‚Ç¨  | 214.09‚Ç¨ | +192% |
| R¬≤       | 0.75    | -0.35  | -147% |
| MAPE     | 17.98%  | 43.90% | +144% |

### Changements de corr√©lations

**Corr√©lations significativement alt√©r√©es :**
- `AgeVehicule` : -0.549 ‚Üí -0.175 (affaiblissement de 68%)
- `BonusMalus` : 0.360 ‚Üí 0.115 (baisse de 68%)

## üîß Utilisation

### Pr√©requis

```bash
pip install pandas numpy scikit-learn lightgbm matplotlib seaborn joblib
```

### Ex√©cution des analyses

1. **Exploration initiale** :
```bash
jupyter notebook notebooks/01_exploration_initiale.ipynb
```

2. **Analyse univari√©e** :
```bash
jupyter notebook notebooks/02_analyse_univariee.ipynb
```

3. **Analyse bivari√©e** :
```bash
jupyter notebook notebooks/03_analyse_bivariee.ipynb
```

4. **Entra√Ænement des mod√®les** :
```bash
jupyter notebook notebooks/04_model_training.ipynb
```

5. **Analyse de d√©rive** :
```bash
jupyter notebook notebooks/05_drift_analysis.ipynb
```

### G√©n√©ration des pr√©dictions

```python
from src.model import predict_test
import joblib

# Charger les mod√®les
glm_model = joblib.load('models/glm_model.pkl')
lgbm_model = joblib.load('models/lgbm_model.pkl')

# G√©n√©rer les pr√©dictions
predict_test({'glm': glm_model, 'lgbm': lgbm_model})
```

## üìä R√©sultats et insights

### Facteurs cl√©s influen√ßant les primes

1. **√Çge du v√©hicule** : Corr√©lation n√©gative forte (-0.55)
2. **Bonus/Malus** : Corr√©lation positive mod√©r√©e (0.36)
3. **√Çge du conducteur** : Corr√©lation n√©gative faible (-0.21)

### Patterns de d√©rive identifi√©s

1. **√âvolution temporelle naturelle** : Changement des habitudes de consommation
2. **Changement de client√®le** : Nouveaux segments de march√©
3. **Contexte externe** : Facteurs macro-√©conomiques ou r√©glementaires
4. **Biais d'√©chantillonnage** : Diff√©rences dans les canaux d'acquisition

### Recommandations

1. **Surveillance continue** : Mise en place d'un monitoring de d√©rive
2. **R√©entra√Ænement p√©riodique** : Adaptation des mod√®les aux nouvelles donn√©es
3. **Feature engineering** : Cr√©ation de variables plus robustes au temps
4. **Ensemble methods** : Combinaison de mod√®les pour am√©liorer la robustesse

## üéØ Conclusion

Ce projet d√©montre l'importance de la d√©tection de d√©rive dans les mod√®les de machine learning appliqu√©s √† l'assurance. Les r√©sultats montrent que m√™me des mod√®les performants initialement peuvent subir une d√©gradation significative face aux changements temporels dans les donn√©es.

L'analyse r√©v√®le que les variables comportementales et temporelles sont plus sensibles √† la d√©rive que les caract√©ristiques structurelles, sugg√©rant une √©volution naturelle du march√© de l'assurance plut√¥t qu'un biais m√©thodologique.

**Auteur** : Lucas Bonere  
**Date** : 2025 
**Technologies** : Python, Scikit-learn, LightGBM, Pandas, Matplotlib, Seaborn 